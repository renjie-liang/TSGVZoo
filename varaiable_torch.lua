label_embs : torch.Size([128, 4])
text_encoder.word_emb.pad_vec : torch.Size([1, 300])
text_encoder.word_emb.unk_vec : torch.Size([1, 300])
text_encoder.word_emb.glove_vec : torch.Size([1269, 300])
text_encoder.char_emb.char_emb.weight : torch.Size([36, 100])
text_encoder.char_emb.char_convs.0.0.weight : torch.Size([10, 100, 1, 1])
text_encoder.char_emb.char_convs.0.0.bias : torch.Size([10])
text_encoder.char_emb.char_convs.1.0.weight : torch.Size([20, 100, 1, 2])
text_encoder.char_emb.char_convs.1.0.bias : torch.Size([20])
text_encoder.char_emb.char_convs.2.0.weight : torch.Size([30, 100, 1, 3])
text_encoder.char_emb.char_convs.2.0.bias : torch.Size([30])
text_encoder.char_emb.char_convs.3.0.weight : torch.Size([40, 100, 1, 4])
text_encoder.char_emb.char_convs.3.0.bias : torch.Size([40])
text_encoder.query_conv1d.conv1d.weight : torch.Size([128, 400, 1])
text_encoder.query_conv1d.conv1d.bias : torch.Size([128])
text_encoder.q_layer_norm.weight : torch.Size([128])
text_encoder.q_layer_norm.bias : torch.Size([128])
video_affine.video_conv1d.conv1d.weight : torch.Size([128, 1024, 1])
video_affine.video_conv1d.conv1d.bias : torch.Size([128])
video_affine.v_layer_norm.weight : torch.Size([128])
video_affine.v_layer_norm.bias : torch.Size([128])
feat_encoder.pos_embedding.position_embeddings.weight : torch.Size([64, 128])
feat_encoder.conv_block.depthwise_separable_conv.0.0.weight : torch.Size([128, 1, 7])
feat_encoder.conv_block.depthwise_separable_conv.0.1.weight : torch.Size([128, 128, 1])
feat_encoder.conv_block.depthwise_separable_conv.0.1.bias : torch.Size([128])
feat_encoder.conv_block.depthwise_separable_conv.1.0.weight : torch.Size([128, 1, 7])
feat_encoder.conv_block.depthwise_separable_conv.1.1.weight : torch.Size([128, 128, 1])
feat_encoder.conv_block.depthwise_separable_conv.1.1.bias : torch.Size([128])
feat_encoder.conv_block.depthwise_separable_conv.2.0.weight : torch.Size([128, 1, 7])
feat_encoder.conv_block.depthwise_separable_conv.2.1.weight : torch.Size([128, 128, 1])
feat_encoder.conv_block.depthwise_separable_conv.2.1.bias : torch.Size([128])
feat_encoder.conv_block.depthwise_separable_conv.3.0.weight : torch.Size([128, 1, 7])
feat_encoder.conv_block.depthwise_separable_conv.3.1.weight : torch.Size([128, 128, 1])
feat_encoder.conv_block.depthwise_separable_conv.3.1.bias : torch.Size([128])
feat_encoder.conv_block.layer_norms.0.weight : torch.Size([128])
feat_encoder.conv_block.layer_norms.0.bias : torch.Size([128])
feat_encoder.conv_block.layer_norms.1.weight : torch.Size([128])
feat_encoder.conv_block.layer_norms.1.bias : torch.Size([128])
feat_encoder.conv_block.layer_norms.2.weight : torch.Size([128])
feat_encoder.conv_block.layer_norms.2.bias : torch.Size([128])
feat_encoder.conv_block.layer_norms.3.weight : torch.Size([128])
feat_encoder.conv_block.layer_norms.3.bias : torch.Size([128])
dual_attention_block_1.layer_norm_1.weight : torch.Size([128])
dual_attention_block_1.layer_norm_1.bias : torch.Size([128])
dual_attention_block_1.layer_norm_2.weight : torch.Size([128])
dual_attention_block_1.layer_norm_2.bias : torch.Size([128])
dual_attention_block_1.layer_norm_t.weight : torch.Size([128])
dual_attention_block_1.layer_norm_t.bias : torch.Size([128])
dual_attention_block_1.dense_1.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dense_1.conv1d.bias : torch.Size([128])
dual_attention_block_1.dense_2.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dense_2.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.query.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.query.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.f_key.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.f_key.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.f_value.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.f_value.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.t_key.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.t_key.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.t_value.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.t_value.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.s_dense.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.s_dense.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.x_dense.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.x_dense.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.s_gate.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.s_gate.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.x_gate.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.x_gate.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.guided_dense.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.guided_dense.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.bilinear_1.bias_value : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.bilinear_1.dense_1.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.bilinear_1.dense_1.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.bilinear_1.dense_2.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.bilinear_1.dense_2.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.bilinear_2.bias_value : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.bilinear_2.dense_1.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.bilinear_2.dense_1.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.bilinear_2.dense_2.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.bilinear_2.dense_2.conv1d.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.layer_norm1.weight : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.layer_norm1.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.layer_norm2.weight : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.layer_norm2.bias : torch.Size([128])
dual_attention_block_1.dual_multihead_attention.out_layer.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_1.dual_multihead_attention.out_layer.conv1d.bias : torch.Size([128])
dual_attention_block_2.layer_norm_1.weight : torch.Size([128])
dual_attention_block_2.layer_norm_1.bias : torch.Size([128])
dual_attention_block_2.layer_norm_2.weight : torch.Size([128])
dual_attention_block_2.layer_norm_2.bias : torch.Size([128])
dual_attention_block_2.layer_norm_t.weight : torch.Size([128])
dual_attention_block_2.layer_norm_t.bias : torch.Size([128])
dual_attention_block_2.dense_1.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dense_1.conv1d.bias : torch.Size([128])
dual_attention_block_2.dense_2.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dense_2.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.query.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.query.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.f_key.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.f_key.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.f_value.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.f_value.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.t_key.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.t_key.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.t_value.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.t_value.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.s_dense.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.s_dense.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.x_dense.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.x_dense.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.s_gate.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.s_gate.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.x_gate.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.x_gate.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.guided_dense.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.guided_dense.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.bilinear_1.bias_value : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.bilinear_1.dense_1.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.bilinear_1.dense_1.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.bilinear_1.dense_2.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.bilinear_1.dense_2.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.bilinear_2.bias_value : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.bilinear_2.dense_1.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.bilinear_2.dense_1.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.bilinear_2.dense_2.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.bilinear_2.dense_2.conv1d.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.layer_norm1.weight : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.layer_norm1.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.layer_norm2.weight : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.layer_norm2.bias : torch.Size([128])
dual_attention_block_2.dual_multihead_attention.out_layer.conv1d.weight : torch.Size([128, 128, 1])
dual_attention_block_2.dual_multihead_attention.out_layer.conv1d.bias : torch.Size([128])
q2v_attn.w4C : torch.Size([128, 1])
q2v_attn.w4Q : torch.Size([128, 1])
q2v_attn.w4mlu : torch.Size([1, 1, 128])
q2v_attn.cqa_linear.conv1d.weight : torch.Size([128, 512, 1])
q2v_attn.cqa_linear.conv1d.bias : torch.Size([128])
v2q_attn.w4C : torch.Size([128, 1])
v2q_attn.w4Q : torch.Size([128, 1])
v2q_attn.w4mlu : torch.Size([1, 1, 128])
v2q_attn.cqa_linear.conv1d.weight : torch.Size([128, 512, 1])
v2q_attn.cqa_linear.conv1d.bias : torch.Size([128])
cq_cat.weighted_pool.weight : torch.Size([128, 1])
cq_cat.conv1d.conv1d.weight : torch.Size([128, 256, 1])
cq_cat.conv1d.conv1d.bias : torch.Size([128])
match_conv1d.conv1d.weight : torch.Size([4, 128, 1])
match_conv1d.conv1d.bias : torch.Size([4])


predictor.feature_encoder.pos_embedding.position_embeddings.weight : torch.Size([64, 128])
predictor.feature_encoder.conv_block.depthwise_separable_conv.0.0.weight : torch.Size([128, 1, 7])
predictor.feature_encoder.conv_block.depthwise_separable_conv.0.1.weight : torch.Size([128, 128, 1])
predictor.feature_encoder.conv_block.depthwise_separable_conv.0.1.bias : torch.Size([128])
predictor.feature_encoder.conv_block.depthwise_separable_conv.1.0.weight : torch.Size([128, 1, 7])
predictor.feature_encoder.conv_block.depthwise_separable_conv.1.1.weight : torch.Size([128, 128, 1])
predictor.feature_encoder.conv_block.depthwise_separable_conv.1.1.bias : torch.Size([128])
predictor.feature_encoder.conv_block.depthwise_separable_conv.2.0.weight : torch.Size([128, 1, 7])
predictor.feature_encoder.conv_block.depthwise_separable_conv.2.1.weight : torch.Size([128, 128, 1])
predictor.feature_encoder.conv_block.depthwise_separable_conv.2.1.bias : torch.Size([128])
predictor.feature_encoder.conv_block.depthwise_separable_conv.3.0.weight : torch.Size([128, 1, 7])
predictor.feature_encoder.conv_block.depthwise_separable_conv.3.1.weight : torch.Size([128, 128, 1])
predictor.feature_encoder.conv_block.depthwise_separable_conv.3.1.bias : torch.Size([128])
predictor.feature_encoder.conv_block.layer_norms.0.weight : torch.Size([128])
predictor.feature_encoder.conv_block.layer_norms.0.bias : torch.Size([128])
predictor.feature_encoder.conv_block.layer_norms.1.weight : torch.Size([128])
predictor.feature_encoder.conv_block.layer_norms.1.bias : torch.Size([128])
predictor.feature_encoder.conv_block.layer_norms.2.weight : torch.Size([128])
predictor.feature_encoder.conv_block.layer_norms.2.bias : torch.Size([128])
predictor.feature_encoder.conv_block.layer_norms.3.weight : torch.Size([128])
predictor.feature_encoder.conv_block.layer_norms.3.bias : torch.Size([128])
predictor.feature_encoder.layer_norm_1.weight : torch.Size([128])
predictor.feature_encoder.layer_norm_1.bias : torch.Size([128])
predictor.feature_encoder.layer_norm_2.weight : torch.Size([128])
predictor.feature_encoder.layer_norm_2.bias : torch.Size([128])
predictor.feature_encoder.top_self_attention.selfattn.in_proj_weight : torch.Size([384, 128])
predictor.feature_encoder.top_self_attention.selfattn.in_proj_bias : torch.Size([384])
predictor.feature_encoder.top_self_attention.selfattn.out_proj.weight : torch.Size([128, 128])
predictor.feature_encoder.top_self_attention.selfattn.out_proj.bias : torch.Size([128])


predictor.feature_encoder.dense.conv1d.weight : torch.Size([128, 128, 1])
predictor.feature_encoder.dense.conv1d.bias : torch.Size([128])



predictor.start_layer_norm.weight : torch.Size([128])
predictor.start_layer_norm.bias : torch.Size([128])
predictor.end_layer_norm.weight : torch.Size([128])
predictor.end_layer_norm.bias : torch.Size([128])


predictor.start_hidden.conv1d.weight : torch.Size([128, 256, 1])
predictor.start_hidden.conv1d.bias : torch.Size([128])

predictor.end_hidden.conv1d.weight : torch.Size([128, 256, 1])
predictor.end_hidden.conv1d.bias : torch.Size([128])

predictor.start_dense.conv1d.weight : torch.Size([1, 128, 1])
predictor.start_dense.conv1d.bias : torch.Size([1])

predictor.end_dense.conv1d.weight : torch.Size([1, 128, 1])
predictor.end_dense.conv1d.bias : torch.Size([1])
